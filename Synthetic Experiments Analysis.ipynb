{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c64e63-f039-48f2-a882-79a6b86f478e",
   "metadata": {},
   "source": [
    "# Analysis of the Experiments of Data Drift Detection methods being applied to Synthetic Data streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fb4df-84a9-4ab2-81d0-145d18209a04",
   "metadata": {},
   "source": [
    "#### Import data and set some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3629e849-a3be-4ec8-849a-fc041a34c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pandas needs to read the consolidated_results.csv\n",
    "df = pd.read_csv(\"comparison_results/consolidated_results.csv\")\n",
    "\n",
    "# we need to filter just the synthetic datasets\n",
    "df = df[df[\"type_of_dataset\"].str.contains(\"synthetic\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b881180-d0b5-4892-b959-2262ba643072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_per_group(df, metric_to_optimize):\n",
    "    \"\"\"\n",
    "    Prints the best results per group for each algorithm based on a specified metric.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The input dataframe containing data for all algorithms.\n",
    "    - metric_to_optimize (str): The column name of the metric to optimize.\n",
    "    \"\"\"\n",
    "    # Iterate through each unique algorithm in the dataframe\n",
    "    for algorithm in df['algorithm'].unique():\n",
    "        print(f\"Algorithm: {algorithm}\\n\")\n",
    "        \n",
    "        # Slice the dataframe for the current algorithm\n",
    "        df_algorithm = df[df['algorithm'] == algorithm]\n",
    "\n",
    "        # Iterate through each unique scenario within the current algorithm\n",
    "        for scenario in df_algorithm['scenario'].unique():\n",
    "            print(f\"  Scenario: {scenario}\\n\")\n",
    "\n",
    "            df_scenario = df_algorithm[df_algorithm['algorithm'] == algorithm]\n",
    "        \n",
    "            # Group by specified columns and select the best row per group based on the metric_to_optimize\n",
    "            best_per_group = (\n",
    "                df_scenario.groupby([\"drift_alignment_with_batch\", \"batch_size\"], as_index=False)\n",
    "                .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            \n",
    "            # Print the desired columns for the best results\n",
    "            print(best_per_group[[\"batch_size\", \"drift_alignment_with_batch\", \"technique\", metric_to_optimize]])\n",
    "            print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a73eff00-68eb-4f9b-ad9b-065652bc7ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(20000 / (3 * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c9936-6163-4521-9afa-519ef99eff7a",
   "metadata": {},
   "source": [
    "## Quick look at the datasets\n",
    "\n",
    "This notebook initially is looking at the experiment with dataset size = 80000, drift length = 20000, drifts in 3 features, with 2 repeating cycle of drifts. Each window: has drift_length / (n_features_with_drift * drift_repeats) \n",
    "\n",
    "The added drifts are all abrupt.\n",
    "\n",
    "Considering batch size as 1000, this is how the sliding drift inside batches work:\n",
    "\n",
    "### 5% of drift inside the batch\n",
    "![5% of drift inside a batch](comparison_results/synthetic_dataset_with_parallel_drifts/feature_plots/synthetic_dataset_with_parallel_drifts_feature1_parallel_drifts_and_batches_1000_0.05.png)\n",
    "\n",
    "### 50% of drift inside the first batch\n",
    "![50% of drift inside a batch](comparison_results/synthetic_dataset_with_parallel_drifts/feature_plots/synthetic_dataset_with_parallel_drifts_feature1_parallel_drifts_and_batches_1000_0.5.png)\n",
    "\n",
    "### 100% of drift inside the first batch\n",
    "![100% of drift inside a batch](comparison_results/synthetic_dataset_with_parallel_drifts/feature_plots/synthetic_dataset_with_parallel_drifts_feature1_parallel_drifts_and_batches_1000_1.0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e79649-1ee7-433b-8b65-2155ae4f7686",
   "metadata": {},
   "source": [
    "### 100% of drift inside the first batch - parallel\n",
    "\n",
    "![100% of drift inside a batch](comparison_results/synthetic_dataset_with_parallel_drifts/feature_plots/synthetic_dataset_with_parallel_drifts_all_features_parallel_drifts_and_batches_1000_1.0.png)\n",
    "\n",
    "### 100% of drift inside the first batch - switching\n",
    "\n",
    "![100% of drift inside a batch](comparison_results/synthetic_dataset_with_switching_drifts/feature_plots/synthetic_dataset_with_switching_drifts_all_features_switching_drifts_and_batches_1000_1.0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d35fc-f618-44a4-92b3-b2916218a782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13963c94-3dcc-404c-810b-b6394fc2ca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset                        object\n",
       "batch_size                      int64\n",
       "technique                      object\n",
       "accuracy                      float64\n",
       "precision                     float64\n",
       "recall                        float64\n",
       "f1                            float64\n",
       "num_drifts                      int64\n",
       "num_batches                     int64\n",
       "auc                           float64\n",
       "drift_alignment_with_batch    float64\n",
       "scenario                       object\n",
       "type_of_dataset                object\n",
       "algorithm                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2c9966f-391b-4a2c-ad15-88c39ed0d0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>technique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>num_drifts</th>\n",
       "      <th>num_batches</th>\n",
       "      <th>auc</th>\n",
       "      <th>drift_alignment_with_batch</th>\n",
       "      <th>scenario</th>\n",
       "      <th>type_of_dataset</th>\n",
       "      <th>algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synthetic_dataset_with_parallel_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>Base</td>\n",
       "      <td>0.642288</td>\n",
       "      <td>0.657160</td>\n",
       "      <td>0.642288</td>\n",
       "      <td>0.633694</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.642383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>parallel_abrupt</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synthetic_dataset_with_parallel_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>KS95</td>\n",
       "      <td>0.652825</td>\n",
       "      <td>0.658354</td>\n",
       "      <td>0.652825</td>\n",
       "      <td>0.649810</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>0.652883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>parallel_abrupt</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synthetic_dataset_with_parallel_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>KS90</td>\n",
       "      <td>0.655238</td>\n",
       "      <td>0.659365</td>\n",
       "      <td>0.655238</td>\n",
       "      <td>0.653027</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.655287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>parallel_abrupt</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>synthetic_dataset_with_parallel_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>HD</td>\n",
       "      <td>0.646175</td>\n",
       "      <td>0.665440</td>\n",
       "      <td>0.646175</td>\n",
       "      <td>0.635645</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0.646281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>parallel_abrupt</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synthetic_dataset_with_parallel_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>JS</td>\n",
       "      <td>0.646175</td>\n",
       "      <td>0.665440</td>\n",
       "      <td>0.646175</td>\n",
       "      <td>0.635645</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0.646281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>parallel_abrupt</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         dataset  batch_size technique  \\\n",
       "0  synthetic_dataset_with_parallel_drifts_abrupt        1000      Base   \n",
       "1  synthetic_dataset_with_parallel_drifts_abrupt        1000      KS95   \n",
       "2  synthetic_dataset_with_parallel_drifts_abrupt        1000      KS90   \n",
       "3  synthetic_dataset_with_parallel_drifts_abrupt        1000        HD   \n",
       "4  synthetic_dataset_with_parallel_drifts_abrupt        1000        JS   \n",
       "\n",
       "   accuracy  precision    recall        f1  num_drifts  num_batches       auc  \\\n",
       "0  0.642288   0.657160  0.642288  0.633694           0           80  0.642383   \n",
       "1  0.652825   0.658354  0.652825  0.649810           8           80  0.652883   \n",
       "2  0.655238   0.659365  0.655238  0.653027          10           80  0.655287   \n",
       "3  0.646175   0.665440  0.646175  0.635645           4           80  0.646281   \n",
       "4  0.646175   0.665440  0.646175  0.635645           4           80  0.646281   \n",
       "\n",
       "   drift_alignment_with_batch         scenario type_of_dataset algorithm  \n",
       "0                         1.0  parallel_abrupt       synthetic        NB  \n",
       "1                         1.0  parallel_abrupt       synthetic        NB  \n",
       "2                         1.0  parallel_abrupt       synthetic        NB  \n",
       "3                         1.0  parallel_abrupt       synthetic        NB  \n",
       "4                         1.0  parallel_abrupt       synthetic        NB  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f5b74-eb3a-481f-a696-3065f1744c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb04baed-6bae-40f9-9ac7-9d8514da45f8",
   "metadata": {},
   "source": [
    "# For each scenario and batch size, what technique performs better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96642ae2-6325-475c-bca1-fb2afbc9d7d6",
   "metadata": {},
   "source": [
    "#### Considering F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "470dd242-ba86-44a4-8ff5-8c4ed41ff25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: NB\n",
      "\n",
      "  Scenario: parallel_abrupt\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique        f1\n",
      "0        1000                         1.0      KS95  0.666145\n",
      "1        1500                         1.0      KS90  0.664691\n",
      "2        2000                         1.0      KS95  0.663312\n",
      "\n",
      "================================================================================\n",
      "\n",
      "  Scenario: switching_incremental\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique        f1\n",
      "0        1000                         1.0      KS95  0.666145\n",
      "1        1500                         1.0      KS90  0.664691\n",
      "2        2000                         1.0      KS95  0.663312\n",
      "\n",
      "================================================================================\n",
      "\n",
      "  Scenario: switching_abrupt\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique        f1\n",
      "0        1000                         1.0      KS95  0.666145\n",
      "1        1500                         1.0      KS90  0.664691\n",
      "2        2000                         1.0      KS95  0.663312\n",
      "\n",
      "================================================================================\n",
      "\n",
      "  Scenario: no_drifts\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique        f1\n",
      "0        1000                         1.0      KS95  0.666145\n",
      "1        1500                         1.0      KS90  0.664691\n",
      "2        2000                         1.0      KS95  0.663312\n",
      "\n",
      "================================================================================\n",
      "\n",
      "  Scenario: parallel_incremental\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique        f1\n",
      "0        1000                         1.0      KS95  0.666145\n",
      "1        1500                         1.0      KS90  0.664691\n",
      "2        2000                         1.0      KS95  0.663312\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n",
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n",
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n",
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n",
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n"
     ]
    }
   ],
   "source": [
    "print_best_per_group(df ,\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6c9da-6184-462d-9d64-252fb8d56d62",
   "metadata": {},
   "source": [
    "#### Considering AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ca35556-3734-4336-bae8-2f4fe4a3733e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: NB\n",
      "\n",
      "  Scenario: parallel_abrupt\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique       auc\n",
      "0        1000                         1.0      KS95  0.668780\n",
      "1        1500                         1.0      KS90  0.667027\n",
      "2        2000                         1.0      KS95  0.665740\n",
      "\n",
      "================================================================================\n",
      "\n",
      "  Scenario: switching_incremental\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique       auc\n",
      "0        1000                         1.0      KS95  0.668780\n",
      "1        1500                         1.0      KS90  0.667027\n",
      "2        2000                         1.0      KS95  0.665740\n",
      "\n",
      "================================================================================\n",
      "\n",
      "  Scenario: switching_abrupt\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique       auc\n",
      "0        1000                         1.0      KS95  0.668780\n",
      "1        1500                         1.0      KS90  0.667027\n",
      "2        2000                         1.0      KS95  0.665740\n",
      "\n",
      "================================================================================\n",
      "\n",
      "  Scenario: no_drifts\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique       auc\n",
      "0        1000                         1.0      KS95  0.668780\n",
      "1        1500                         1.0      KS90  0.667027\n",
      "2        2000                         1.0      KS95  0.665740\n",
      "\n",
      "================================================================================\n",
      "\n",
      "  Scenario: parallel_incremental\n",
      "\n",
      "   batch_size  drift_alignment_with_batch technique       auc\n",
      "0        1000                         1.0      KS95  0.668780\n",
      "1        1500                         1.0      KS90  0.667027\n",
      "2        2000                         1.0      KS95  0.665740\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n",
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n",
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n",
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n",
      "/var/folders/5f/sx30p29n23d2bq0_yfm62z4h0000gn/T/ipykernel_42356/3976136182.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.loc[group[metric_to_optimize].idxmax()])\n"
     ]
    }
   ],
   "source": [
    "print_best_per_group(df, \"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266bcc31-1c25-47b4-8e55-daa0dc82f5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17993df7-27cc-4984-a5df-d82d64b6a8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff84a755-0810-4193-b566-d22717a7e1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d71c17ac-4f1b-4a85-8428-a326951a747b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_abrupt_drift_1.0_batch_2000\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |   12 |    7 |    0 |       0.632 |      1   |      0.774 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |   12 |    8 |    0 |       0.6   |      1   |      0.75  |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    6 |    7 |    6 |       0.462 |      0.5 |      0.48  |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    6 |    7 |    6 |       0.462 |      0.5 |      0.48  |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_abrupt_drift_1.0_batch_1000\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |    4 |    4 |    4 |         0.5 |     0.5  |      0.5   |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |    4 |    6 |    4 |         0.4 |     0.5  |      0.444 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    2 |    2 |    6 |         0.5 |     0.25 |      0.333 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    2 |    2 |    6 |         0.5 |     0.25 |      0.333 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_incremental_drift_1.0_batch_1500\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |   19 |    5 |    0 |       0.792 |    1     |      0.884 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |   19 |    6 |    0 |       0.76  |    1     |      0.864 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |   11 |    4 |    8 |       0.733 |    0.579 |      0.647 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |   11 |    4 |    8 |       0.733 |    0.579 |      0.647 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_abrupt_drift_1.0_batch_1500\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |   17 |    6 |    2 |       0.739 |    0.895 |      0.81  |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |   17 |    7 |    2 |       0.708 |    0.895 |      0.791 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    7 |    6 |   12 |       0.538 |    0.368 |      0.438 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    7 |    6 |   12 |       0.538 |    0.368 |      0.438 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_incremental_drift_1.0_batch_1000\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |    8 |    4 |    0 |       0.667 |     1    |      0.8   |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |    8 |    6 |    0 |       0.571 |     1    |      0.727 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    2 |    2 |    6 |       0.5   |     0.25 |      0.333 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    2 |    2 |    6 |       0.5   |     0.25 |      0.333 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_incremental_drift_1.0_batch_2000\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |    4 |    3 |    0 |       0.571 |      1   |      0.727 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |    4 |    4 |    0 |       0.5   |      1   |      0.667 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    2 |    3 |    2 |       0.4   |      0.5 |      0.444 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    2 |    3 |    2 |       0.4   |      0.5 |      0.444 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_abrupt_drift_1.0_batch_1000\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |   15 |    6 |   11 |       0.714 |    0.577 |      0.638 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |   15 |    6 |   11 |       0.714 |    0.577 |      0.638 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    9 |    7 |   17 |       0.562 |    0.346 |      0.429 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    9 |    7 |   17 |       0.562 |    0.346 |      0.429 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_incremental_drift_1.0_batch_1000\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |   25 |    5 |    1 |       0.833 |    0.962 |      0.893 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |   25 |    5 |    1 |       0.833 |    0.962 |      0.893 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |   12 |    5 |   14 |       0.706 |    0.462 |      0.558 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |   11 |    5 |   15 |       0.688 |    0.423 |      0.524 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_incremental_drift_1.0_batch_1500\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |    6 |    3 |    0 |       0.667 |      1   |      0.8   |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |    6 |    5 |    0 |       0.545 |      1   |      0.706 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    3 |    4 |    3 |       0.429 |      0.5 |      0.462 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    3 |    3 |    3 |       0.5   |      0.5 |      0.5   |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_abrupt_drift_1.0_batch_2000\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |    4 |    3 |    0 |       0.571 |      1   |      0.727 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |    4 |    4 |    0 |       0.5   |      1   |      0.667 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    2 |    3 |    2 |       0.4   |      0.5 |      0.444 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    2 |    3 |    2 |       0.4   |      0.5 |      0.444 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_incremental_drift_1.0_batch_2000\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |   12 |    7 |    0 |       0.632 |    1     |      0.774 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |   12 |    8 |    0 |       0.6   |    1     |      0.75  |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    4 |    7 |    8 |       0.364 |    0.333 |      0.348 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    3 |    7 |    9 |       0.3   |    0.25  |      0.273 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_abrupt_drift_1.0_batch_1500\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| Method       |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==============+======+======+======+=============+==========+============+\n",
      "| ks_drifts    |    5 |    3 |    1 |       0.625 |    0.833 |      0.714 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| ks_90_drifts |    5 |    5 |    1 |       0.5   |    0.833 |      0.625 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| hd_drifts    |    3 |    5 |    3 |       0.375 |    0.5   |      0.429 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "| js_drifts    |    3 |    4 |    3 |       0.429 |    0.5   |      0.462 |\n",
      "+--------------+------+------+------+-------------+----------+------------+\n",
      "Results saved to /Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/drift_detection_results.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the JSON data from the file\n",
    "file_path = \"/Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/consolidated_drift_results.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Function to compute performance metrics\n",
    "def compute_metrics(true_drifts, detected_drifts):\n",
    "    TP = len(detected_drifts & true_drifts)  # True positives\n",
    "    FP = len(detected_drifts - true_drifts)  # False positives\n",
    "    FN = len(true_drifts - detected_drifts)  # False negatives\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"F1-score\": round(f1_score, 3)\n",
    "    }\n",
    "\n",
    "# Process each scenario\n",
    "results = {}\n",
    "\n",
    "for scenario in data:\n",
    "    dataset_name = scenario[\"dataset\"]\n",
    "    drift_within_batch = scenario[\"drift_within_batch\"]\n",
    "    batch_size = scenario[\"batch_size\"]\n",
    "    scenario_id = f\"{dataset_name}_drift_{drift_within_batch}_batch_{batch_size}\"\n",
    "\n",
    "    # Aggregate all synthetic drifts from different features\n",
    "    true_drifts = set.union(*[set(batches) for batches in scenario[\"synthetic_drifts\"].values()])\n",
    "\n",
    "    # Compute performance metrics for each detection method\n",
    "    metrics = {method: compute_metrics(true_drifts, set(detected_batches))\n",
    "               for method, detected_batches in scenario[\"detected_drifts\"].items()}\n",
    "\n",
    "    # Store results\n",
    "    results[scenario_id] = metrics\n",
    "\n",
    "# Save results to CSV file\n",
    "csv_file = \"/Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/drift_detection_results.csv\"\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Scenario\", \"Method\", \"TP\", \"FP\", \"FN\", \"Precision\", \"Recall\", \"F1-score\"])\n",
    "    for scenario, metrics in results.items():\n",
    "        for method, scores in metrics.items():\n",
    "            writer.writerow([scenario, method, scores[\"TP\"], scores[\"FP\"], scores[\"FN\"], scores[\"Precision\"], scores[\"Recall\"], scores[\"F1-score\"]])\n",
    "\n",
    "# Print results in structured table format\n",
    "for scenario, metrics in results.items():\n",
    "    print(f\"\\nScenario: {scenario}\")\n",
    "    table_data = [[method, scores[\"TP\"], scores[\"FP\"], scores[\"FN\"], scores[\"Precision\"], scores[\"Recall\"], scores[\"F1-score\"]]\n",
    "                  for method, scores in metrics.items()]\n",
    "    headers = [\"Method\", \"TP\", \"FP\", \"FN\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "print(f\"Results saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0342fef-2394-4cce-927f-a0b386138d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f255006-e296-4d0d-82dd-3584cddae4e8",
   "metadata": {},
   "source": [
    "# New results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe8ec5e6-f378-4c28-9817-bca0df6b5539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_incremental_drift_1.0_batch_2500\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |    4 |    3 |    0 |       0.571 |      1   |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |    4 |    3 |    0 |       0.571 |      1   |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    2 |    0 |    2 |       1     |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    2 |    0 |    2 |       1     |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_incremental_drift_1.0_batch_2500\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |   13 |    5 |    1 |       0.722 |    0.929 |      0.813 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |   13 |    5 |    1 |       0.722 |    0.929 |      0.813 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    6 |    4 |    8 |       0.6   |    0.429 |      0.5   |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    6 |    4 |    8 |       0.6   |    0.429 |      0.5   |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_incremental_drift_1.0_batch_1000\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |   24 |    6 |    2 |       0.8   |    0.923 |      0.857 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |   24 |    6 |    2 |       0.8   |    0.923 |      0.857 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |   10 |    7 |   16 |       0.588 |    0.385 |      0.465 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    9 |    7 |   17 |       0.562 |    0.346 |      0.429 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_abrupt_drift_1.0_batch_2500\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |    4 |    3 |    0 |       0.571 |        1 |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |    4 |    3 |    0 |       0.571 |        1 |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    4 |    0 |    0 |       1     |        1 |      1     |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    4 |    0 |    0 |       1     |        1 |      1     |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_abrupt_drift_1.0_batch_2500\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |   12 |    5 |    2 |       0.706 |    0.857 |      0.774 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |   12 |    5 |    2 |       0.706 |    0.857 |      0.774 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    4 |    0 |   10 |       1     |    0.286 |      0.444 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    4 |    0 |   10 |       1     |    0.286 |      0.444 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_switching_drifts_abrupt_drift_1.0_batch_1000\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |   15 |    6 |   11 |       0.714 |    0.577 |      0.638 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |   15 |    6 |   11 |       0.714 |    0.577 |      0.638 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |   11 |    5 |   15 |       0.688 |    0.423 |      0.524 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |   11 |    5 |   15 |       0.688 |    0.423 |      0.524 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_incremental_drift_1.0_batch_1000\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |    8 |    4 |    0 |       0.667 |      1   |      0.8   |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |    8 |    6 |    0 |       0.571 |      1   |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    4 |    0 |    4 |       1     |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    4 |    0 |    4 |       1     |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: synthetic_dataset_with_parallel_drifts_abrupt_drift_1.0_batch_1000\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |    4 |    4 |    4 |         0.5 |      0.5 |      0.5   |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |    4 |    6 |    4 |         0.4 |      0.5 |      0.444 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    4 |    0 |    4 |         1   |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    4 |    0 |    4 |         1   |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "Results saved to /Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/drift_detection_results.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the JSON data from the file\n",
    "file_path = \"/Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/consolidated_drift_results.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Function to compute performance metrics\n",
    "def compute_metrics(true_drifts, detected_drifts):\n",
    "    TP = len(detected_drifts & true_drifts)  # True positives\n",
    "    FP = len(detected_drifts - true_drifts)  # False positives\n",
    "    FN = len(true_drifts - detected_drifts)  # False negatives\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"F1-score\": round(f1_score, 3)\n",
    "    }\n",
    "\n",
    "# Process each scenario\n",
    "results = {}\n",
    "\n",
    "# Map for method mapping\n",
    "method_mapping = {\n",
    "    \"ks_drifts\": \"KS95\", \n",
    "    \"ks_90_drifts\": \"KS90\",\n",
    "    \"hd_drifts\": \"HD\",\n",
    "    \"js_drifts\": \"JS\"\n",
    "}\n",
    "\n",
    "for scenario in data:\n",
    "    dataset_name = scenario[\"dataset\"]\n",
    "    drift_within_batch = scenario[\"drift_within_batch\"]\n",
    "    batch_size = scenario[\"batch_size\"]\n",
    "    scenario_id = f\"{dataset_name}_drift_{drift_within_batch}_batch_{batch_size}\"\n",
    "\n",
    "    # Aggregate all synthetic drifts from different features\n",
    "    true_drifts = set.union(*[set(batches) for batches in scenario[\"synthetic_drifts\"].values()])\n",
    "\n",
    "    # Compute performance metrics for each detection method, applying method_mapping\n",
    "    metrics = {method_mapping.get(method, method): compute_metrics(true_drifts, set(detected_batches))\n",
    "               for method, detected_batches in scenario[\"detected_drifts\"].items()}\n",
    "\n",
    "    # Store results\n",
    "    results[scenario_id] = metrics\n",
    "\n",
    "\n",
    "# Save results to CSV file\n",
    "csv_file = \"/Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/drift_detection_results.csv\"\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Scenario\", \"Method\", \"TP\", \"FP\", \"FN\", \"Precision\", \"Recall\", \"F1-score\"])\n",
    "    for scenario, metrics in results.items():\n",
    "        for method, scores in metrics.items():\n",
    "            writer.writerow([scenario, method, scores[\"TP\"], scores[\"FP\"], scores[\"FN\"], scores[\"Precision\"], scores[\"Recall\"], scores[\"F1-score\"]])\n",
    "\n",
    "# Print results in structured table format\n",
    "for scenario, metrics in results.items():\n",
    "    print(f\"\\nScenario: {scenario}\")\n",
    "    table_data = [[method, scores[\"TP\"], scores[\"FP\"], scores[\"FN\"], scores[\"Precision\"], scores[\"Recall\"], scores[\"F1-score\"]]\n",
    "                  for method, scores in metrics.items()]\n",
    "    headers = [\"Method\", \"TP\", \"FP\", \"FN\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "print(f\"Results saved to {csv_file}\")\n",
    "\n",
    "\n",
    "# Example: synthetic_dataset_with_switching_drifts_abrupt_drift_1.0_batch_2000\n",
    "# string_format = f\"{dataset_id}_{amount_of_drift_in_batch}_batch_{batch_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb2619-f1d8-4c37-98ac-34a969be82b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b24e91-aeba-4108-a7df-8830be2d4393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53f40587-9586-4603-93bd-0b75d92a98a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario: SYN-SI, Amount of Drift: 1.0, Batch Size: 2500\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |   13 |    5 |    1 |       0.722 |    0.929 |      0.813 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |   13 |    5 |    1 |       0.722 |    0.929 |      0.813 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    6 |    4 |    8 |       0.6   |    0.429 |      0.5   |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    6 |    4 |    8 |       0.6   |    0.429 |      0.5   |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: SYN-PA, Amount of Drift: 1.0, Batch Size: 1000\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |    4 |    4 |    4 |         0.5 |      0.5 |      0.5   |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |    4 |    6 |    4 |         0.4 |      0.5 |      0.444 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    4 |    0 |    4 |         1   |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    4 |    0 |    4 |         1   |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: SYN-SI, Amount of Drift: 1.0, Batch Size: 1000\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |   24 |    6 |    2 |       0.8   |    0.923 |      0.857 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |   24 |    6 |    2 |       0.8   |    0.923 |      0.857 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |   10 |    7 |   16 |       0.588 |    0.385 |      0.465 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    9 |    7 |   17 |       0.562 |    0.346 |      0.429 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: SYN-PI, Amount of Drift: 1.0, Batch Size: 1000\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |    8 |    4 |    0 |       0.667 |      1   |      0.8   |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |    8 |    6 |    0 |       0.571 |      1   |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    4 |    0 |    4 |       1     |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    4 |    0 |    4 |       1     |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: SYN-PI, Amount of Drift: 1.0, Batch Size: 2500\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |    4 |    3 |    0 |       0.571 |      1   |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |    4 |    3 |    0 |       0.571 |      1   |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    2 |    0 |    2 |       1     |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    2 |    0 |    2 |       1     |      0.5 |      0.667 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: SYN-SA, Amount of Drift: 1.0, Batch Size: 2500\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |   12 |    5 |    2 |       0.706 |    0.857 |      0.774 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |   12 |    5 |    2 |       0.706 |    0.857 |      0.774 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    4 |    0 |   10 |       1     |    0.286 |      0.444 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    4 |    0 |   10 |       1     |    0.286 |      0.444 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: SYN-PA, Amount of Drift: 1.0, Batch Size: 2500\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |    4 |    3 |    0 |       0.571 |        1 |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |    4 |    3 |    0 |       0.571 |        1 |      0.727 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |    4 |    0 |    0 |       1     |        1 |      1     |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |    4 |    0 |    0 |       1     |        1 |      1     |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "\n",
      "Scenario: SYN-SA, Amount of Drift: 1.0, Batch Size: 1000\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| Method   |   TP |   FP |   FN |   Precision |   Recall |   F1-score |\n",
      "+==========+======+======+======+=============+==========+============+\n",
      "| KS95     |   15 |    6 |   11 |       0.714 |    0.577 |      0.638 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| KS90     |   15 |    6 |   11 |       0.714 |    0.577 |      0.638 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| HD       |   11 |    5 |   15 |       0.688 |    0.423 |      0.524 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "| JS       |   11 |    5 |   15 |       0.688 |    0.423 |      0.524 |\n",
      "+----------+------+------+------+-------------+----------+------------+\n",
      "Results saved to /Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/drift_detection_results.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the JSON data from the file\n",
    "file_path = \"/Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/consolidated_drift_results.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Function to compute performance metrics\n",
    "def compute_metrics(true_drifts, detected_drifts):\n",
    "    TP = len(detected_drifts & true_drifts)  # True positives\n",
    "    FP = len(detected_drifts - true_drifts)  # False positives\n",
    "    FN = len(true_drifts - detected_drifts)  # False negatives\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"F1-score\": round(f1_score, 3)\n",
    "    }\n",
    "\n",
    "# Process each scenario\n",
    "results = {}\n",
    "\n",
    "# Map for method mapping\n",
    "method_mapping = {\n",
    "    \"ks_drifts\": \"KS95\", \n",
    "    \"ks_90_drifts\": \"KS90\",\n",
    "    \"hd_drifts\": \"HD\",\n",
    "    \"js_drifts\": \"JS\"\n",
    "}\n",
    "\n",
    "for scenario in data:\n",
    "    dataset_name = scenario[\"dataset\"]\n",
    "    drift_within_batch = scenario[\"drift_within_batch\"]\n",
    "    batch_size = scenario[\"batch_size\"]\n",
    "    scenario_id = f\"{dataset_name}_drift_{drift_within_batch}_batch_{batch_size}\"\n",
    "\n",
    "    # Aggregate all synthetic drifts from different features\n",
    "    true_drifts = set.union(*[set(batches) for batches in scenario[\"synthetic_drifts\"].values()])\n",
    "\n",
    "    # Compute performance metrics for each detection method, applying method_mapping\n",
    "    metrics = {method_mapping.get(method, method): compute_metrics(true_drifts, set(detected_batches))\n",
    "               for method, detected_batches in scenario[\"detected_drifts\"].items()}\n",
    "\n",
    "    # Store results\n",
    "    results[scenario_id] = metrics\n",
    "\n",
    "# Dataset mapping\n",
    "dataset_mapping = {\n",
    "    \"synthetic_dataset_no_drifts\": \"SYN\",\n",
    "    \"synthetic_dataset_with_parallel_drifts_abrupt\": \"SYN-PA\",\n",
    "    \"synthetic_dataset_with_parallel_drifts_incremental\": \"SYN-PI\",\n",
    "    \"synthetic_dataset_with_switching_drifts_abrupt\": \"SYN-SA\",\n",
    "    \"synthetic_dataset_with_switching_drifts_incremental\": \"SYN-SI\"\n",
    "}\n",
    "\n",
    "# Save results to CSV file with new format\n",
    "csv_file = \"/Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/drift_detection_results.csv\"\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Updated headers\n",
    "    writer.writerow([\"Dataset\", \"Amount of Drift\", \"Batch Size\", \"Method\", \"TP\", \"FP\", \"FN\", \"Precision\", \"Recall\", \"F1-score\"])\n",
    "    \n",
    "    for scenario, metrics in results.items():\n",
    "        # Extract dataset, amount_of_drift_in_batch, and batch_size\n",
    "        parts = scenario.split(\"_drift_\")\n",
    "        dataset_id = parts[0]  # e.g., synthetic_dataset_with_switching_drifts_abrupt\n",
    "        rest = parts[1].split(\"_batch_\")\n",
    "        amount_of_drift_in_batch = rest[0]  # e.g., 1.0\n",
    "        batch_size = rest[1]  # e.g., 2000\n",
    "\n",
    "        # Map dataset ID\n",
    "        dataset_name = dataset_mapping.get(dataset_id, dataset_id)  # Default to original if not found\n",
    "        \n",
    "        for method, scores in metrics.items():\n",
    "            writer.writerow([dataset_name, amount_of_drift_in_batch, batch_size, method,\n",
    "                             scores[\"TP\"], scores[\"FP\"], scores[\"FN\"],\n",
    "                             scores[\"Precision\"], scores[\"Recall\"], scores[\"F1-score\"]])\n",
    "\n",
    "# Print results in structured table format\n",
    "for scenario, metrics in results.items():\n",
    "    # Extract dataset, amount_of_drift_in_batch, and batch_size\n",
    "    parts = scenario.split(\"_drift_\")\n",
    "    dataset_id = parts[0]\n",
    "    rest = parts[1].split(\"_batch_\")\n",
    "    amount_of_drift_in_batch = rest[0]\n",
    "    batch_size = rest[1]\n",
    "\n",
    "    # Map dataset ID\n",
    "    dataset_name = dataset_mapping.get(dataset_id, dataset_id)\n",
    "\n",
    "    print(f\"\\nScenario: {dataset_name}, Amount of Drift: {amount_of_drift_in_batch}, Batch Size: {batch_size}\")\n",
    "\n",
    "    table_data = [\n",
    "        [method, scores[\"TP\"], scores[\"FP\"], scores[\"FN\"], scores[\"Precision\"], scores[\"Recall\"], scores[\"F1-score\"]]\n",
    "        for method, scores in metrics.items()\n",
    "    ]\n",
    "    \n",
    "    headers = [\"Method\", \"TP\", \"FP\", \"FN\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "\n",
    "print(f\"Results saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e19cee32-f22a-4b0a-84ae-edfbc6642865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\caption{Precision, Recall, and F1-score for a batch size of 2500.}\n",
      "\\centering\n",
      "\\begin{tabular*}{\\textwidth}{@{}l c c c c@{}}\n",
      "\\hline \\hline\n",
      "Dataset & Technique & Precision & Recall & F1-score \\\\ \n",
      "\\hline\n",
      "SYN-SI & KS95 & 0.722 & 0.929 & 0.813 \\\\\n",
      "SYN-SI & KS90 & 0.722 & 0.929 & 0.813 \\\\\n",
      "SYN-SI & HD & 0.6 & 0.429 & 0.5 \\\\\n",
      "SYN-SI & JS & 0.6 & 0.429 & 0.5 \\\\\n",
      "SYN-PI & KS95 & 0.571 & 1.0 & 0.727 \\\\\n",
      "SYN-PI & KS90 & 0.571 & 1.0 & 0.727 \\\\\n",
      "SYN-PI & HD & 1.0 & 0.5 & 0.667 \\\\\n",
      "SYN-PI & JS & 1.0 & 0.5 & 0.667 \\\\\n",
      "SYN-SA & KS95 & 0.706 & 0.857 & 0.774 \\\\\n",
      "SYN-SA & KS90 & 0.706 & 0.857 & 0.774 \\\\\n",
      "SYN-SA & HD & 1.0 & 0.286 & 0.444 \\\\\n",
      "SYN-SA & JS & 1.0 & 0.286 & 0.444 \\\\\n",
      "SYN-PA & KS95 & 0.571 & 1.0 & 0.727 \\\\\n",
      "SYN-PA & KS90 & 0.571 & 1.0 & 0.727 \\\\\n",
      "SYN-PA & HD & 1.0 & 1.0 & 1.0 \\\\\n",
      "SYN-PA & JS & 1.0 & 1.0 & 1.0 \\\\\n",
      "\\hline \\hline\n",
      "\\end{tabular}\n",
      "\\label{tab:metrics_2500}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def generate_latex_table(csv_file, batch_size):\n",
    "    # Read CSV file\n",
    "    data = []\n",
    "    with open(csv_file, mode=\"r\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row[\"Batch Size\"] == str(batch_size):  # Filter by batch size\n",
    "                data.append(row)\n",
    "\n",
    "    if not data:\n",
    "        return f\"No data found for batch size {batch_size}.\"\n",
    "\n",
    "    # LaTeX Table Header\n",
    "    latex_code = f\"\"\"\\\\begin{{table}}[ht]\n",
    "\\\\caption{{Precision, Recall, and F1-score for a batch size of {batch_size}.}}\n",
    "\\\\centering\n",
    "\\\\begin{{tabular*}}{{\\\\textwidth}}{{@{{}}l c c c c@{{}}}}\n",
    "\\\\hline \\\\hline\n",
    "Dataset & Technique & Precision & Recall & F1-score \\\\\\\\ \n",
    "\\\\hline\n",
    "\"\"\"\n",
    "\n",
    "    # Fill in the table rows\n",
    "    for row in data:\n",
    "        dataset = row[\"Dataset\"]\n",
    "        method = row[\"Method\"]\n",
    "        precision = row[\"Precision\"]\n",
    "        recall = row[\"Recall\"]\n",
    "        f1_score = row[\"F1-score\"]\n",
    "        \n",
    "        latex_code += f\"{dataset} & {method} & {precision} & {recall} & {f1_score} \\\\\\\\\\n\"\n",
    "\n",
    "    # Table Footer\n",
    "    latex_code += \"\"\"\\\\hline \\\\hline\n",
    "\\\\end{tabular}\n",
    "\\\\label{tab:metrics_\"\"\" + str(batch_size) + \"\"\"}\n",
    "\\\\end{table}\"\"\"\n",
    "\n",
    "    return latex_code\n",
    "\n",
    "# Example usage:\n",
    "csv_file_path = \"/Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/drift_detection_results.csv\"\n",
    "batch_size_input = 2500\n",
    "latex_table = generate_latex_table(csv_file_path, batch_size_input)\n",
    "\n",
    "# Print or save the LaTeX table\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1c856-6256-468b-89d5-5b6e3ccb90da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4113af-0f8c-46f0-9b06-18604b5bcb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_file = \"/Users/lucashelfstein/Documents/Masters/EmpiricalAnalysisOfDataDrift/comparison_results/consolidated_results.csv\"\n",
    "\n",
    "df_results = pd.read_csv(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b082c8be-bc5e-486f-acad-7ddc11e68c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results[['dataset', 'batch_size', 'technique','f1', 'auc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1e1265-8f6e-4ef9-93c0-2767a13ea582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>technique</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>Base</td>\n",
       "      <td>0.645339</td>\n",
       "      <td>0.649492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>KS95</td>\n",
       "      <td>0.662664</td>\n",
       "      <td>0.664268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>KS90</td>\n",
       "      <td>0.662664</td>\n",
       "      <td>0.664268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>HD</td>\n",
       "      <td>0.657067</td>\n",
       "      <td>0.660815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1000</td>\n",
       "      <td>JS</td>\n",
       "      <td>0.657067</td>\n",
       "      <td>0.660815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1500</td>\n",
       "      <td>Base</td>\n",
       "      <td>0.643748</td>\n",
       "      <td>0.647577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1500</td>\n",
       "      <td>KS95</td>\n",
       "      <td>0.656290</td>\n",
       "      <td>0.658158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1500</td>\n",
       "      <td>KS90</td>\n",
       "      <td>0.657017</td>\n",
       "      <td>0.658693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1500</td>\n",
       "      <td>HD</td>\n",
       "      <td>0.654753</td>\n",
       "      <td>0.657063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>1500</td>\n",
       "      <td>JS</td>\n",
       "      <td>0.654753</td>\n",
       "      <td>0.657063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2000</td>\n",
       "      <td>Base</td>\n",
       "      <td>0.641535</td>\n",
       "      <td>0.645036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2000</td>\n",
       "      <td>KS95</td>\n",
       "      <td>0.650006</td>\n",
       "      <td>0.652325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2000</td>\n",
       "      <td>KS90</td>\n",
       "      <td>0.649784</td>\n",
       "      <td>0.652176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2000</td>\n",
       "      <td>HD</td>\n",
       "      <td>0.649639</td>\n",
       "      <td>0.651508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2000</td>\n",
       "      <td>JS</td>\n",
       "      <td>0.649639</td>\n",
       "      <td>0.651508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2500</td>\n",
       "      <td>Base</td>\n",
       "      <td>0.640320</td>\n",
       "      <td>0.643735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2500</td>\n",
       "      <td>KS95</td>\n",
       "      <td>0.650072</td>\n",
       "      <td>0.651578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2500</td>\n",
       "      <td>KS90</td>\n",
       "      <td>0.650072</td>\n",
       "      <td>0.651578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2500</td>\n",
       "      <td>HD</td>\n",
       "      <td>0.642816</td>\n",
       "      <td>0.647269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>synthetic_dataset_with_switching_drifts_abrupt</td>\n",
       "      <td>2500</td>\n",
       "      <td>JS</td>\n",
       "      <td>0.642816</td>\n",
       "      <td>0.647269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dataset  batch_size technique  \\\n",
       "340  synthetic_dataset_with_switching_drifts_abrupt        1000      Base   \n",
       "341  synthetic_dataset_with_switching_drifts_abrupt        1000      KS95   \n",
       "342  synthetic_dataset_with_switching_drifts_abrupt        1000      KS90   \n",
       "343  synthetic_dataset_with_switching_drifts_abrupt        1000        HD   \n",
       "344  synthetic_dataset_with_switching_drifts_abrupt        1000        JS   \n",
       "345  synthetic_dataset_with_switching_drifts_abrupt        1500      Base   \n",
       "346  synthetic_dataset_with_switching_drifts_abrupt        1500      KS95   \n",
       "347  synthetic_dataset_with_switching_drifts_abrupt        1500      KS90   \n",
       "348  synthetic_dataset_with_switching_drifts_abrupt        1500        HD   \n",
       "349  synthetic_dataset_with_switching_drifts_abrupt        1500        JS   \n",
       "350  synthetic_dataset_with_switching_drifts_abrupt        2000      Base   \n",
       "351  synthetic_dataset_with_switching_drifts_abrupt        2000      KS95   \n",
       "352  synthetic_dataset_with_switching_drifts_abrupt        2000      KS90   \n",
       "353  synthetic_dataset_with_switching_drifts_abrupt        2000        HD   \n",
       "354  synthetic_dataset_with_switching_drifts_abrupt        2000        JS   \n",
       "355  synthetic_dataset_with_switching_drifts_abrupt        2500      Base   \n",
       "356  synthetic_dataset_with_switching_drifts_abrupt        2500      KS95   \n",
       "357  synthetic_dataset_with_switching_drifts_abrupt        2500      KS90   \n",
       "358  synthetic_dataset_with_switching_drifts_abrupt        2500        HD   \n",
       "359  synthetic_dataset_with_switching_drifts_abrupt        2500        JS   \n",
       "\n",
       "           f1       auc  \n",
       "340  0.645339  0.649492  \n",
       "341  0.662664  0.664268  \n",
       "342  0.662664  0.664268  \n",
       "343  0.657067  0.660815  \n",
       "344  0.657067  0.660815  \n",
       "345  0.643748  0.647577  \n",
       "346  0.656290  0.658158  \n",
       "347  0.657017  0.658693  \n",
       "348  0.654753  0.657063  \n",
       "349  0.654753  0.657063  \n",
       "350  0.641535  0.645036  \n",
       "351  0.650006  0.652325  \n",
       "352  0.649784  0.652176  \n",
       "353  0.649639  0.651508  \n",
       "354  0.649639  0.651508  \n",
       "355  0.640320  0.643735  \n",
       "356  0.650072  0.651578  \n",
       "357  0.650072  0.651578  \n",
       "358  0.642816  0.647269  \n",
       "359  0.642816  0.647269  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.dataset == 'synthetic_dataset_with_switching_drifts_abrupt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e9f93-ebad-4c7e-8007-66245c246ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de86b8c-a00a-4011-bfb6-421657380a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
